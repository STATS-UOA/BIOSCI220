[["index.html", "Module I BIOSCI220, University of Auckland Preface 0.1 Course Overview: BIOSCI220 0.2 Module 1: Key Topics 0.3 Timetable &amp; Assessment (Modules I, II, and III)", " Module I BIOSCI220, University of Auckland Charlotte Jones-Todd Semester 1, 2021 Preface Artwork by @allison_horst 0.1 Course Overview: BIOSCI220 Living systems are the most complex things in the Universe. The science of biology is therefore the science of the complex. Other sciences, like physics and chemistry, have simpler study subjects. This may surprise students who think of other sciences as difficult and maths-heavy, and think of biology as science but with less maths. However, biological research has actually been heavily quantitative for 100+ years. Much of the development of the field of statistics was driven by and for biologists and their research problems, which usually have a large amount of natural variability. In recent decades, the computational revolution has spread to every part of biology, and all biological fields now rely heavily on analyses that would be impossible without computers and computer programming: &quot;big data&quot; studies and complex models of biological phenomena. Therefore, in order to understand modern biological research and findings, and to participate in this research (and get jobs!), it is now essential for biology students to acquire skills in working with and visualising data, learning from data using models, and generating data using simulations of models. These might be classic statistical models, simulation models, or inference with process-based models. Most importantly, students need to gain the ability to be careful and critical thinkers about data and how it is acquired, as well as the ability to think critically about the models that we use to try to simplify, and thereby understand, the incredible complexity of biology. 0.2 Module 1: Key Topics Data Exploration and Statistical Inference Data wrangling and visualisation. Introduction to R, importing and plotting data, R packages Experimental design and introduction to linear models Linear models with multiple variables; model interpretation Interpretation of p-values; model critique and model comparison Large data, exploratory data analysis, introduction to clustering and dimensionality reduction Slides here 0.3 Timetable &amp; Assessment (Modules I, II, and III) Lectures Monday 9‚Äì10am Labs Monday 2‚Äì5pm Tuesday 10am‚Äì1pm Thursday 10am‚Äì1pm Friday 10am‚Äì1pm Lab exercises 60% Total (11 labs in Total; 6 for Module 1, weeks 1--6) Due weekly by 5pm Weekly quizzes 10% Total (11 quizzes in Total; 5 for Module 1, weeks 2--6) Due weekly by 5pm Final Exam 30% "],["r-and-rstudio.html", "1 R and RStudio 1.1 Learning Objectives 1.2 Introduction to R and RStudio 1.3 Exploratory Data Analysis (EDA) 1.4 Other resources: optional but recommended", " 1 R and RStudio The purpose of this chapter is to get you started learning a new language! Throughout BIOSCI220 you will be introduced to tools required to critically analyse and interpret biological data. Throughout this module you will be expected to use R and RStudio weekly. It is highly recommended that you familiarise yourself with these environments using the computer on which you plan to carry out the majority of your work. If this is a lab computer then R and RStudio will already been installed. If you choose to use these then you should still complete the exercises below to familiarise yourself with the software. Another option available is the use of RStudio Cloud; here, everything is run in a web browser (on a remote server) and doesn't require you to download the software onto your personal computer. However, if you plan to use your personal computer then you will need to install both R and RStudio. Follow the directions in Installing R and RStudio to do so. 1.1 Learning Objectives Define the difference between R and RStudio Express the benefits and issues associated with these software being used in the scientific community. Specifically, summarise the benefits and drawbacks associated with the open-source paradigm, discuss the concept of reproducible research and outline its importance Distinguish between different data types (e.g., integers, characters, logical, numerical) Explain what an R function is; describe what an argument to an R function is Explain what an R package is; distinguish between the functions install.packages() and library() Explain what a working directory is in the context of R Interpret and fix basic R errors. For example ## Error in library(fiddler): there is no package called &#39;fiddler&#39; and ## Warning in file(file, &quot;rt&quot;): cannot open file &#39;paua.csv&#39;: No such file or ## directory ## Error in file(file, &quot;rt&quot;): cannot open the connection Use the appropriate R function to read in a .csv data; carry out basic exploratory data analysis using tidyverse (use the pipe operator, %&gt;% when summarising a data.frame); create simple plots of the data. 1.2 Introduction to R and RStudio R is the pheromone to RStudio's PDA. R is a language, specifically, a programming language; it's the way you can speak to your computer to ask it to carry out certain computations. RStudio is an integrated development environment (IDE). This means it is basically an interface, albeit a fancy one, that makes it easier to communicate with your computer in the language R. The main benefit is the additional features it has that enable you to more efficiently speak R. Note R and RStudio are two different pieces of software; for this course you are expected to download both. As you'd expect, the PDA depends on the pheromones (i.e., RStudio depends on R) so you have to download R to use RStudio! 1.2.1 Why? The selling pitch of this course states that ...biological research has actually been heavily quantitative for 100+ years... and promises that ...it is now essential for biology students to acquire skills in working with and visualising data, learning from data using models.... We're not making it up! If you need convincing that quantitative and programming skills are essential to graduate in all scientific disciplines have a read of the following. The Popularity of Data Science Software Why R? 1.2.1.1 WhyR? It's free It's open source A general-purpose of programming language Written by statisticians (here in Auckland!) It's available for all operating systems (Windows, Linux, and Mac) There is a huge online support network It's extremely flexible; if you can code it you can do it! 15,000+ packages available! ... 1.2.1.2 Why RStudio? &quot;If R were an airplane, RStudio would be the airport...&quot; --- Julie Lowndes, Introduction to RStudio Awesomeness Speaks nicely to R Tab completion Debugging capabilities There is a huge online support network Offers many other features and tools to make your workflow with R easier It facilitates reproducibility ... 1.2.2 Installing R and RStudio As mentioned above RStudio depends on R so there is an order you should follow when you download these software. Download and install R by following these instructions. Make sure you choose the correct operating system; if you are unsure then please ask either a TA or myself. Download and install RStudio by going here choosing RStudio Desktop Open Source License Free and following instructions. Again if you are unsure then please ask either a TA or myself. Check all is working Open up RStudio from your computer menu, the icon will look something like this (DO NOT use this icon , this is a link to R and will only open a very basic interface) Wait a little and you should see RStudio open up to something similar to the screenshot below Pay close attention to the notes in the screenshot and familiarise yourself with the terms. Finally, in the Console next to the prompt type 1:10 and press enter on your keyboard. Your computer should say something back you (in the Console)! What do you think you were asking it to do? Does the output make sense?1 If you get stuck at any of the steps above then please ask either a TA or myself. It is imperative for the rest of the course that you complete the steps above. 1.2.2.1 Good practice* Always start with a clean workspace Why? *So your ex (code) can't come and mess up your life!** Go to Tools &gt; Global Options Project-oriented workflow. Recommended: .Rproj Organised Set up each Each assignment/university course as a project Self-contained a project is a folder that contains all relevant files All paths can then be relative to that project Reproducible the project should just work on a different computer Got to Project (top right) &gt; New Project &gt; Create Project Project set-up ‚ö†Ô∏èWarning‚ö†Ô∏è Jenny Bryan will set your computer on fire üî• if you start your script like this rm(list = ls()) This does NOT create a fresh R process it makes your script vulnerable it will come back to bite you 1.2.3 Getting started As in step 3. above open up RStudio from your computer menu, the icon will look something like this . Using the diagram above identify the different panes: Console where you directly type command in and communicate with your computer (via the language R). Environment pane Files pane Some terminology Running code: the act of telling R to perform an act by giving it commands in the console. Objects: where values are saved in (see later for creating an object. Script: a text file containing a set of commands and comments. Comments: notes written within a Script to better document/explain what's happening 1.2.4 R Scripts (a .r file) Go File &gt; New File &gt; R Script to open up a new Script If you had only three panes showing before, a new (fourth) pane should open up in the top left of RStudio. This file will have a .r extension and is where you can write, edit, and save the R commands you write. It's a dedicated text editor for your R code (very useful if you want to save your code to run at a later date). The main difference between typing your code into a Script vs Console is that you edit it and save it for later! Remember though the Console is the pane where you communicate with your computer so all code you write will have to be Run here. There are two ways of running a line of code you've written in your Script Ensure your cursor is on the line of code you want to run, hold down Ctrl and press Enter. Ensure your cursor is on the line of code you want to run, then use your mouse to click the Run button (it has a green arrow next to it) on the top right of the Script pane. Type 1:10 in your Script and practise running this line of code using both methods above. Not that if you've Run the code successfully then your computer will speak back to you each time via the Console 1.2.5 Writing Comments Comments are notes to yourself (future or present) or to someone else and are, typically, written interspersed in your code. Now, the comments you write will typically be in a language your computer doesn't understand (e.g., English). So that you can write yourself notes in your Script you need to tell your computer using the R language to ignore them. To do this precede any note you write with #, see below. The # is R for ignore anything after this character. ## IGNORE ME ## I&#39;m a comment ## I repeat I&#39;m a comment ## I am not a cat ## OK let&#39;s run some code 2 + 2 ## [1] 4 ## Hmm maybe I should check this ## @kareem_carr ;-) Now remember when you want to leave your R session you'll need to Save your Script to use it again. To do this go File &gt; Save As and name your file what you wish (remember too to choose a relevant folder on your computer, or as recommended use the .Rproj set-up as above). 1.2.6 Data types Artwork by @allison_horst Here we're covering data types in R (e.g., integers, doubles/numeric, logical, and characters). Integers are whole values like 1, 0, 220. These are classified &quot;integer&quot; or int in R. Numeric values are a larger set of values containing integers but also fractions and decimal values, for example -56.94 and 1.3. These are classified &quot;numeric&quot; or num or dbl in R. Logicals are either TRUE or FALSE. These are classified &quot;logical&quot; or lgl in R. Characters are text such as ‚ÄúCharlotte‚Äù, ‚ÄúBIOSCI220‚Äù, and ‚ÄúStatistics is the greatest subject ever‚Äù. Note that characters are denoted with the quotation marks around them and are classified &quot;character&quot; or chr in R. ## As an example we&#39;re going to as our computer using R what it classified the character string &quot;Charlotte&quot; as class(&quot;Charlotte&quot;) ## [1] &quot;character&quot; 1.2.7 Creating Objects Objects are created values using the symbols &lt;- (an arrow formed out of &lt; and -). Like we, typically, write an equation the left-hand side is the Object we're defining (creating) and the right-hand side is the stuff we're defining it as. For example, below I'm creating the Object my_name and assigning it the character string of my first name. my_name &lt;- &quot;Charlotte&quot; So now the Object my_name ‚Äòcontains‚Äô the value &quot;Charlotte&quot;. Another assignment to the same object will overwrite the content. my_name &lt;- &quot;Moragh&quot; To check the content of an Object you can simply as your computer to print it out for you (in R). my_name ## [1] &quot;Moragh&quot; Note: R is case sensitive: it treats my_name and My_Name as different objects. An object can be assigned a collection of things: my_names &lt;- c(&quot;Charlotte&quot;, &quot;Moragh&quot;, &quot;Jones-Todd&quot;) my_names ## [1] &quot;Charlotte&quot; &quot;Moragh&quot; &quot;Jones-Todd&quot; some_numbers &lt;- c(1,4,5,13,45,90) some_numbers ## [1] 1 4 5 13 45 90 An Object can also be an entire dataset, see Exploratory Data Analysis (EDA) below. 1.2.8 R functions Functions (or commands) perform tasks in R. They take in inputs called arguments and return outputs. You can either manually specify a function‚Äôs arguments or use the function‚Äôs default values. For example, the function seq() in R generates a sequence of numbers. If you just run seq() it will return the value 1. That doesn‚Äôt seem very useful! This is because the default arguments are set as seq(from = 1, to = 1). Thus, if you don't pass in different values for from and to to change this behaviour, your computer just assumes all you want is the number 1. You can change the argument values by updating the values after the = sign. If we try out seq(from = 2, to = 5) we get the result rseq(from = 2, to = 5)` that we might expect. 1.2.9 R packages An R package is simply a collection of functions! Typically all focused on a particular type of procedure. The base installation of R comes with many useful packages as standard and these packages will contain many of the functions you will use on a daily basis (e.g., mean(), length()). However, often we wish to do more than base R offer! To do this we need to access all the other amazing packages there are in the Rverse. CRAN is like a centralised library with thousands of books in stock. To access the contents of a book (package) you first need to request it for (install it into) your local library (your computer) Your can only access books in your local library. install.packages(&#39;the.package.name&#39;) To access the knowledge in a particular book (use the function is the package) you need to tell your computer via R to go get the book of the shelf. Then you have access to all the functions it contains! library(the.package.name) 1.2.10 R Errors Sometimes rather than doing what you expect it to your computer will return an Error message to you via the Console prefaced with **Error in...* followed by text that will try to explain what went wrong. This, generally, means something has gone wrong, so what do you do? Read it! THE MESSAGES ARE WRITTEN IN PLAIN ENGLISH (MOSTLY) DO NOT continue running bits of code hoping the issue will go away. IT WILL NOT. Try and work out what it means and fix it by: reading the documentation, see [] search or ask questions on Stack Overflow or RStudio Community Sometimes your computer will return a warning messages to you prefaced &quot;Warning:&quot;. These can sometimes be ignored as they may not affect us. However, READ THE MESSAGE and decide for yourself. Occasionally, also your computer will write you a friendly message, just keeping you up-to date with what it's doing, again don't ignore these they might be telling you something useful! 1.2.11 Working directories You need to tell your computer where to look! Look at the top of your Console. You will see something like ~/Desktop/ or C://Users/... (it won't be an exact match of course). This is the 'address' of where your computer is looking. Now, run getwd() and see what output you get (it will be the same as written on the top of your Console pane. This is because getwd() stands for get the current workingdirectory (i.e., the current directory you are currently working in) e.g., getwd() ## [1] &quot;/home/charlotte/Git/BIOSCI220/docs&quot; You should ensure that you are aware of which directory you're working in (which folder RStudio is looking in by default) as this is important later on when we come to reading in files and saving our work! 1.2.11.1 Changing address So you're not where you want to be! Click Session &gt; Set Working Directory &gt; Choose Directory &gt; Chose where you want to go Now notice that something has been written in your Console something similar to setwd(&quot;~/Git/BIOSCI220/data&quot;). Now setwd() stands for set your workingdirectory. If you know the address of the directory you want to work in without having to point-and-click you could use this command directly, in this case you've used the point-and-click to do it and RStudio has helpfully written out your choices as an R command. 1.2.12 Getting help [Where to go?] Let's say we want to learn more about the function mean() (we can take a wild guess at what it calculates, but... what if we didn't know for sure. There are two ways we can ask within RStudio ?mean() or help(mean) Try both and see what pops up in your right-hand bottom pane! Failing that Google is (often) your friend 1.3 Exploratory Data Analysis (EDA) To finish off this section and to ensure you're all set to go for the rest of the module we're going to carry out some exploratory data analysis and visualisations on some real-world data :-) For this module we will be using tidyverse. 'tidyverse' is a collection of R packages that all share underlying design philosophy, grammar, and data structures. They are specifically designed to make data wrangling, manipulation, visualisation, and analysis simpler. To install all the packages that belong to the tidyverse run ## request (download) the tidyverse packages from the centralised library install.packages(&quot;tidyverse&quot;) To tell your computer to access the tidyverse functionality in your session run (Note you'll have to do this each time you start up an R session): ## Get the tidyverse packages from our local library ## Do this every time you start a new session ## and want to use the tidyverse! library(tidyverse) 1.3.1 Reading in data from a .csv file First off download the paua.csv file from CANVAS onto your computer (remember which folder you saved it in!) To read the data into RStudio In the Environment pane click Import Dataset &gt; ** From Text (readr)** &gt; Browse &gt; Choose your file, remembering which folder you downloaded it to &gt; Another pane should pop up, check the data looks as you might expect &gt; Import You should now notice that in the Environment pane there is something listed under Data (this is the name of the data.frame Object containing the data we will explore) Now notice how in the Console a few lines of code have been added. These are the commands you were telling your computer via the point-and-click procedure you went through! Notice the character string inside read_csv()... This is the full 'address' of your data (the folder you saved it in). When you tell your computer to look for something you need to tell it exactly where it is! Remember the getwd() command above, this tells you the default location RStudio will look for a file, if your file is not in this folder you have to tell it the full address. 1.3.2 Using functions to explore the data Automatically RStudio has run the command View() for you. This makes your dataset show itself in the top left pane. It's like looking at the data in Excel. Follow along with the commands below, I recommend that you open up a new Script and use that to write and save your commands for later. Don't forget to ensure you have read the paua into your session (all commands below assume that your data Object is called paua, if you've called it something different then just replace paua with whatever you've called it below. Now let's go ahead and use some functions to ask and answer questions about our data. The first thing you should always do is view any data frames you import. Let's have a look at your data in the Console paua ## # A tibble: 60 x 3 ## Species Length Age ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Haliotis iris 1.8 1.50 ## 2 Haliotis australis 5.4 11.9 ## 3 Haliotis australis 4.8 5.42 ## 4 Haliotis iris 5.75 4.50 ## 5 Haliotis iris 5.65 5.50 ## 6 Haliotis iris 2.8 2.50 ## 7 Haliotis australis 5.9 6.49 ## 8 Haliotis iris 3.75 5.00 ## 9 Haliotis australis 7.2 8.56 ## 10 Haliotis iris 4.25 5.50 ## # ‚Ä¶ with 50 more rows So, what does this show us? A tibble: 60 x 3: A tibble is a specific kind of data frame in R. Our paua dataset has 60 rows (i.e., 60 different observations). Here, each observation corresponds to a P\\(\\overline{a}\\)ua shell. 3 columns corresponding to 3 variables describing each observation. Species, Length, and Age are the different variables of this dataset. We then have a preview of the first 10 rows of observations corresponding to the first 10 P\\(\\overline{a}\\)uashells. ``... with 50 more rows indicates there are 50 more rows to see, but these have not been printed (likely as it would clog our screen) Let's look at some other ways of exploring the data. Using the View() command (recall from above) to explore the data in a pop-up viewer View(paua) Using the glimpse() command for an alternative view glimpse(paua) ## Rows: 60 ## Columns: 3 ## $ Species &lt;chr&gt; &quot;Haliotis iris&quot;, &quot;Haliotis australis&quot;, &quot;Haliotis australis&quot;, ‚Ä¶ ## $ Length &lt;dbl&gt; 1.80, 5.40, 4.80, 5.75, 5.65, 2.80, 5.90, 3.75, 7.20, 4.25, 6‚Ä¶ ## $ Age &lt;dbl&gt; 1.497884, 11.877010, 5.416991, 4.497799, 5.500789, 2.500972, ‚Ä¶ glimpse() will give you the first few entries of each variable in a row after the variable name. Note also, that the data type of the variable is given immediately after each variables name inside &lt; &gt;. 1.3.2.1 The pipe operator %&gt;% A nifty tidyverse tool is called the pipe operator %&gt;%. The pipe operator allows us to combine multiple operations in R into a single sequential chain of actions. Say you would like to perform a hypothetical sequence of operations on a hypothetical data frame x using hypothetical functions f(), g(), and h(): This is where the pipe operator %&gt;% comes in handy. %&gt;% takes the output of one function and then ‚Äúpipes‚Äù it to be the input of the next function. Furthermore, a helpful trick is to read %&gt;% as ‚Äúthen‚Äù or ‚Äúand then.‚Äù For example, you can obtain the same output as the hypothetical sequence of functions as follows: x %&gt;% f() %&gt;% g() %&gt;% h() You would read this sequence as: Take x then Use this output as the input to the next function f() then Use this output as the input to the next function g() then Use this output as the input to the next function h() So to calculate the mean Age of each Species in the paua dataset we would use paua %&gt;% group_by(Species) %&gt;% summarize(mean_age = mean(Age)) ## # A tibble: 2 x 2 ## Species mean_age ## * &lt;chr&gt; &lt;dbl&gt; ## 1 Haliotis australis 7.55 ## 2 Haliotis iris 4.40 You would read the sequence above as: Take the paua data.frame then Use this and apply the group_by() function to group by Species Use this output and apply the summarize() function to calculate the mean (using (mean()) Age of each group (Species), calling the resulting number mean_age 1.3.3 Basic plotting (for your own purposes) The payoff is so clear: you make informative plots that help you understand data. boxplot(Age ~ Species, data = paua) So what have we asked our computer to do here? Given what we know about the types of data our paua Object contains what plots do you think would be most appropriate for each variable? Below is some example code; each line of code will produce a plot (perhaps not a sensible one though). What do you think? What is each plot showing us? boxplot(Length ~ Species, data = paua) boxplot(Age ~ Species, data = paua) plot(Age ~ Length, data = paua) boxplot(Age ~ Length, data = paua) plot(paua$Age) 1.4 Other resources: optional but recommended Artwork by @allison_horst R for Data Science RStudio Education An Introduction to R Learning statistics with R: A tutorial for psychology students and other beginners R for Biologists Quantitative Biology: Basic Introduction to R You should have seen the numbers 1 to 10 printed out as a sequence.‚Ü© "],["data-exploration-and-visualization.html", "2 Data exploration and visualization 2.1 Learning objectives 2.2 Data wrangling and manipulation 2.3 Data sovereignty 2.4 Data Viz 2.5 Other resources: optional but recommended", " 2 Data exploration and visualization So now you've been introduced to R and RStudio let's get going with some data manipulation and visualization. Exploring and visualising your data is one of the most important steps. It's also one of the simplest! You'll not find anyone who's not made the mistake of taking their data for granted. Just because someone says it's so NEVER trust that that's the case. From typos, to NAs, through -999 and let's not even talk dates, your data will always have a surprise in store for you. 2.1 Learning objectives Carry out and interpret the outputs of basic exploratory data analysis using in-built R functions Define and discuss MƒÅori Data Sovereignty principles Define data sovereignty and explain this in relation to a researcher's obligation when collecting, displaying, and analysing data Create and communicate informative data visualisations using R Discuss and critique data visualisations 2.2 Data wrangling and manipulation tidy data &quot;Tidy datasets are all alike, but every messy dataset is messy in its own way.&quot; --- Hadley Wickham There are three interrelated rules which make a dataset tidy: Each variable must have its own column Each observation must have its own row Each value must have its own cell Illustration from the Openscapes blog Tidy Data for reproducibility, efficiency, and collaboration by Julia Lowndes and Allison Horst Why ensure that your data is tidy? Consistency: using a consistent format aids learning and reproducibility Simplicity: it's a format that is well understood by R &quot;Tidy datasets are easy to manipulate, model and visualize, and have a specific structure: each variable is a column, each observation is a row, and each type of observational unit is a table. This framework makes it easy to tidy messy datasets because only a small set of tools are needed to deal with a wide range of un-tidy datasets.&quot; --- Hadley Wickham, Tidy data Tidy Data 2.2.1 Introuducing the Palmer penguins library(palmerpenguins) ## contains some nice penguin data penguins ## # A tibble: 344 x 8 ## species island bill_length_mm bill_depth_mm flipper_length_‚Ä¶ body_mass_g ## &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; ## 1 Adelie Torge‚Ä¶ 39.1 18.7 181 3750 ## 2 Adelie Torge‚Ä¶ 39.5 17.4 186 3800 ## 3 Adelie Torge‚Ä¶ 40.3 18 195 3250 ## 4 Adelie Torge‚Ä¶ NA NA NA NA ## 5 Adelie Torge‚Ä¶ 36.7 19.3 193 3450 ## 6 Adelie Torge‚Ä¶ 39.3 20.6 190 3650 ## 7 Adelie Torge‚Ä¶ 38.9 17.8 181 3625 ## 8 Adelie Torge‚Ä¶ 39.2 19.6 195 4675 ## 9 Adelie Torge‚Ä¶ 34.1 18.1 193 3475 ## 10 Adelie Torge‚Ä¶ 42 20.2 190 4250 ## # ‚Ä¶ with 334 more rows, and 2 more variables: sex &lt;fct&gt;, year &lt;int&gt; So, what does this show us? A tibble: 344 x 8: A tibble is a specific kind of data frame in R. The penguin dataset has 344 rows (i.e., 344 different observations). Here, each observation corresponds to a penguin. 8 columns corresponding to 3 variables describing each observation. species, island, bill_length_mm, bill_depth_mm, flipper_length_mm, body_mass_g, sex, and year are the different variables of this dataset. We then have a preview of the first 10 rows of observations corresponding to the first 10 penguins. ``... with 334 more rows indicates there are 334 more rows to see, but these have not been printed (likely as it would clog our screen) To learn more about the penguins read the paper that talks all about the data collection. 2.2.2 Common dataframe manipulations in the tidyverse, using dplyr and tidyr Even from these first few rows of data we can see that there are some NA values. Let's count the number of NAs. Remember the %&gt;% operator? Here we're going to be introduced to a few new things the apply() function, the is.na() function, and how R deals with logical values! library(tidyverse) penguins %&gt;% apply(.,2,is.na) %&gt;% apply(.,2,sum) ## species island bill_length_mm bill_depth_mm ## 0 0 2 2 ## flipper_length_mm body_mass_g sex year ## 2 2 11 0 There's lot going on in that code! Let's break it down Take penguins then Use penguins as an input to the apply() function (this is specified as the first argument using the .) Now the apply() function takes 3 arguments: the data object you want it to apply something to (in our case penguins) the margin you want to apply that something to; 1 stands for rows and 2 stands for columns, and the function you want it to apply (in our case is.na()). So the second line of code is asking R to apply the is.na() function over the columns of penguins is.na() asks for each value it's fed is it an NA value; it returns a TRUE if so and a FALSE otherwise The output from the first apply() is then fed to the second apply() (using the .). The sum() function then add them up! R treats a TRUE as a 1 and a FALSE as a 0. So how many NAs do you think there are! Doesn't help much. To Now we know there are NA values throughout the data let's remove then and create a new NA free version called penguins_nafree. There is a really handy tidyverse (dplyr) function for this! penguins_nafree &lt;- penguins %&gt;% drop_na() penguins_nafree ## # A tibble: 333 x 8 ## species island bill_length_mm bill_depth_mm flipper_length_‚Ä¶ body_mass_g ## &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; ## 1 Adelie Torge‚Ä¶ 39.1 18.7 181 3750 ## 2 Adelie Torge‚Ä¶ 39.5 17.4 186 3800 ## 3 Adelie Torge‚Ä¶ 40.3 18 195 3250 ## 4 Adelie Torge‚Ä¶ 36.7 19.3 193 3450 ## 5 Adelie Torge‚Ä¶ 39.3 20.6 190 3650 ## 6 Adelie Torge‚Ä¶ 38.9 17.8 181 3625 ## 7 Adelie Torge‚Ä¶ 39.2 19.6 195 4675 ## 8 Adelie Torge‚Ä¶ 41.1 17.6 182 3200 ## 9 Adelie Torge‚Ä¶ 38.6 21.2 191 3800 ## 10 Adelie Torge‚Ä¶ 34.6 21.1 198 4400 ## # ‚Ä¶ with 323 more rows, and 2 more variables: sex &lt;fct&gt;, year &lt;int&gt; Below are some other useful manipulation functions; have a look at the out puts and run them yourselves and see if you can work out what they're doing. filter(penguins_nafree, island == &quot;Torgersen&quot; ) ## # A tibble: 47 x 8 ## species island bill_length_mm bill_depth_mm flipper_length_‚Ä¶ body_mass_g ## &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; ## 1 Adelie Torge‚Ä¶ 39.1 18.7 181 3750 ## 2 Adelie Torge‚Ä¶ 39.5 17.4 186 3800 ## 3 Adelie Torge‚Ä¶ 40.3 18 195 3250 ## 4 Adelie Torge‚Ä¶ 36.7 19.3 193 3450 ## 5 Adelie Torge‚Ä¶ 39.3 20.6 190 3650 ## 6 Adelie Torge‚Ä¶ 38.9 17.8 181 3625 ## 7 Adelie Torge‚Ä¶ 39.2 19.6 195 4675 ## 8 Adelie Torge‚Ä¶ 41.1 17.6 182 3200 ## 9 Adelie Torge‚Ä¶ 38.6 21.2 191 3800 ## 10 Adelie Torge‚Ä¶ 34.6 21.1 198 4400 ## # ‚Ä¶ with 37 more rows, and 2 more variables: sex &lt;fct&gt;, year &lt;int&gt; summarise(penguins_nafree, avgerage_bill_length = mean(bill_length_mm)) ## # A tibble: 1 x 1 ## avgerage_bill_length ## &lt;dbl&gt; ## 1 44.0 group_by(penguins_nafree, species) ## # A tibble: 333 x 8 ## # Groups: species [3] ## species island bill_length_mm bill_depth_mm flipper_length_‚Ä¶ body_mass_g ## &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; ## 1 Adelie Torge‚Ä¶ 39.1 18.7 181 3750 ## 2 Adelie Torge‚Ä¶ 39.5 17.4 186 3800 ## 3 Adelie Torge‚Ä¶ 40.3 18 195 3250 ## 4 Adelie Torge‚Ä¶ 36.7 19.3 193 3450 ## 5 Adelie Torge‚Ä¶ 39.3 20.6 190 3650 ## 6 Adelie Torge‚Ä¶ 38.9 17.8 181 3625 ## 7 Adelie Torge‚Ä¶ 39.2 19.6 195 4675 ## 8 Adelie Torge‚Ä¶ 41.1 17.6 182 3200 ## 9 Adelie Torge‚Ä¶ 38.6 21.2 191 3800 ## 10 Adelie Torge‚Ä¶ 34.6 21.1 198 4400 ## # ‚Ä¶ with 323 more rows, and 2 more variables: sex &lt;fct&gt;, year &lt;int&gt; Often we want to summarise variables by different groups (factors). Below we Take the penguins_nafree data then Use this and apply the group_by() function to group by species Use this output and apply the summarize() function to calculate the mean (using (mean()) bill length (bill_length_mm) of each group (species), calling the resulting number avgerage_bill_length penguins_nafree %&gt;% group_by(species) %&gt;% summarise(avgerage_bill_length = mean(bill_length_mm)) ## # A tibble: 3 x 2 ## species avgerage_bill_length ## * &lt;fct&gt; &lt;dbl&gt; ## 1 Adelie 38.8 ## 2 Chinstrap 48.8 ## 3 Gentoo 47.6 We can also group by multiple factors, for example, penguins_nafree %&gt;% group_by(island,species) %&gt;% summarise(avgerage_bill_length = mean(bill_length_mm)) ## `summarise()` has grouped output by &#39;island&#39;. You can override using the `.groups` argument. ## # A tibble: 5 x 3 ## # Groups: island [3] ## island species avgerage_bill_length ## &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; ## 1 Biscoe Adelie 39.0 ## 2 Biscoe Gentoo 47.6 ## 3 Dream Adelie 38.5 ## 4 Dream Chinstrap 48.8 ## 5 Torgersen Adelie 39.0 2.3 Data sovereignty ''Data sovereignty is the idea that data are subject to the laws and governance structures within the nation it is collected'' &quot;For Indigenous peoples, historical encounters with statistics have been fraught, and none more so than when involving official data produced as part of colonial attempts at statecraft.&quot; --- Lovett, R., Lee, V., Kukutai, T., Cormack, D., Rainie, S.C. and Walker, J., 2019. Good data practices for Indigenous data sovereignty and governance. Good data, pp.26-36. 2.3.1 MƒÅori Data Sovereignty principles &quot;MƒÅori Data Sovereignty has emerged as a critical policy issue as Aotearoa New Zealand develops world-leading linked administrative data resources.&quot; --- Andrew Sporle, Maui Hudson, Kiri West. Chapter 5, Indigenous Data Sovereignty and Policy ‚ÄúMƒÅori data refers to data produced by MƒÅori or that is about MƒÅori and the environments we have relationships with.&quot; --- Te Mana Raraunga Charter Data is a ‚Äúpotential taonga, something precious that needs to be maintained, in relation to its utility‚Äù --- Dr W. Edwards, TMR website Article Two of the Treaty of Waitangi obliges the Government to actively protect taonga, consult with MƒÅori in respect of taonga, give effect to the principle of partnership and recognize MƒÅori rangatiratanga over taonga. Factors that relate to how communities might recognize the taonga nature of any dataset include provenance of the data: does the dataset come from a significant MƒÅori source? opportunity for the data: could the dataset support MƒÅori aspirations for their people or their whenua (land)? utility of the data: does the dataset have multiple uses? MƒÅori Data Sovereignty principles to inform the recognition of MƒÅori rights and interests in data, and the ethical use of data to enhance MƒÅori well-being: Rangatiratanga, authority MƒÅori have an inherent right to exercise control over MƒÅori data and MƒÅori data ecosystems. This right includes, but is not limited to, the creation, collection, access, analysis, interpretation, management, security, dissemination, use and reuse of MƒÅori data. Decisions about the physical and virtual storage of MƒÅori data shall enhance control for current and future generations. Whenever possible, MƒÅori data shall be stored in Aotearoa New Zealand. MƒÅori have the right to data that is relevant and empowers sustainable self-determination and effective self-governance Whakapapa, relationships All data has a whakapapa (genealogy). Accurate metadata should, at minimum, provide information about the provenance of the data, the purpose(s) for its collection, the context of its collection, and the parties involved. The ability to disaggregate MƒÅori data increases its relevance for MƒÅori communities and iwi. MƒÅori data shall be collected and coded using categories that prioritise MƒÅori needs and aspirations. Current decision-making over data can have long-term consequences, good and bad, for future generations of MƒÅori. A key goal of MƒÅori data governance should be to protect against future harm. Whanaungatanga, obligations Individuals‚Äô rights (including privacy rights), risks and benefits in relation to data need to be balanced with those of the groups of which they are a part. In some contexts, collective MƒÅori rights will prevail over those of individuals. Individuals and organisations responsible for the creation, collection, analysis, management, access, security or dissemination of MƒÅori data are accountable to the communities, groups and individuals from whom the data derive Kotahitanga, collective benefit Data ecosystems shall be designed and function in ways that enable MƒÅori to derive individual and collective benefit. Build capacity. MƒÅori Data Sovereignty requires the development of a MƒÅori workforce to enable the creation, collection, management, security, governance and application of data. Connections between MƒÅori and other Indigenous peoples shall be supported to enable the sharing of strategies, resources and ideas in relation to data, and the attainment of common goals. Manaakitanga, reciprocity The collection, use and interpretation of data shall uphold the dignity of MƒÅori communities, groups and individuals. Data analysis that stigmatises or blames MƒÅori can result in collective and individual harm and should be actively avoided. Free, prior and informed consent shall underpin the collection and use of all data from or about MƒÅori. Less defined types of consent shall be balanced by stronger governance arrangements. Kaitiakitanga, guardianship MƒÅori data shall be stored and transferred in such a way that it enables and reinforces the capacity of MƒÅori to exercise kaitiakitanga over MƒÅori data. Ethics. Tikanga, kawa (protocols) and mƒÅtauranga (knowledge) shall underpin the protection, access and use of MƒÅori data. MƒÅori shall decide which MƒÅori data shall be controlled (tapu) or open (noa) access. The Te Mana o te Raraunga Model was developed to align MƒÅori concepts with data rights and interests, and guide agencies in the appropriate use of MƒÅori data Whakapapa and whanaungatanga: recognising the connectedness between the material, natural and spiritual worlds Rangatiratanga: mƒÅori rights to own, access, control and possess data from them or about them and their environs Kotahitanga: collective vision and unity of purpose Manaakitanga: ethical data use to progress MƒÅori aspirations for wellbeing Kaitiakitanga: sustainable data stewardship Resourses Lovett, R., Lee, V., Kukutai, T., Cormack, D., Rainie, S.C. and Walker, J., 2019. Good data practices for Indigenous data sovereignty and governance. Good data, pp.26-36. Walter, Maggie, Tahu Kukutai, Stephanie Russo Carroll, and Desi Rodriguez-Lonebear. Indigenous Data Sovereignty and Policy. Taylor &amp; Francis, 2020. 2.4 Data Viz &quot;...have obligations in that we have a great deal of power over how people ultimately make use of data, both in the patterns they see and the conclusions they draw.&quot; --- Michael Correll, Ethical Dimensions of Visualization Research &quot;Clutter and confusion are not attributes of data - they are shortcomings of design.&quot; --- Edward Tufte 2.4.1 Exploratory and explanatory plots Exploratory plots (for you) data exploration doesn't have to look pretty just needs to get to the point explore and discover new data facets formulate new questions Explanatory plots (For others), most common kind of graph used in scientific publications clear purpose designed for the audience make it easy to read (this covers a lot of things) do not distort guide the reader to a particular conclusion answer a specific question support a decision Plots by Cedric Scherer and mentioned on this blog 2.4.2 Ten Simple Rules for Better Figures &quot;Scientific visualization is classically defined as the process of graphically displaying scientific data. However, this process is far from direct or automatic. There are so many different ways to represent the same data: scatter plots, linear plots, bar plots, and pie charts, to name just a few. Furthermore, the same data, using the same type of plot, may be perceived very differently depending on who is looking at the figure. A more accurate definition for scientific visualization would be a graphical interface between people and data.&quot; --- Nicolas P. Rougier, Michael Droettboom, Philip E. Bourne, Ten Simple Rules for Better Figures Know Your Audience Identify Your Message Adapt the Figure to the Support Medium Captions Are Not Optional Do Not Trust the Defaults Use Color Effectively Do Not Mislead the Reader There are formulas to measure how misleading a graph is! Avoid Chartjunk Message Trumps Beauty &quot;message and readability of the figure is the most important aspect while beauty is only an option&quot; --- Nicolas P. Rougier, Michael Droettboom, Philip E. Bourne, Ten Simple Rules for Better Figures Get the Right Tool I'm an advocate for R üòâ So we've seen some pretty plots, let's get around to making some! 2.4.3 Introducing ggplot2 ggplot2 is an R package for producing statistical, or data, graphics; it has an underlying grammar based on the Grammar of Graphics Every ggplot2 plot has three key components: data, A set of aesthetic mappings between variables in the data and visual properties, and At least one layer which describes how to render each observation. Layers are usually created with a geom function. 2.4.3.1 Plotting palmerpenguins You might find this application useful, now and later... We've seen that there are three factor variables in the dataset: species, island, and sex. To count the number of penguins of each species and sex on each island we could use penguins_nafree %&gt;% count(species, sex, island) ## # A tibble: 10 x 4 ## species sex island n ## &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; ## 1 Adelie female Biscoe 22 ## 2 Adelie female Dream 27 ## 3 Adelie female Torgersen 24 ## 4 Adelie male Biscoe 22 ## 5 Adelie male Dream 28 ## 6 Adelie male Torgersen 23 ## 7 Chinstrap female Dream 34 ## 8 Chinstrap male Dream 34 ## 9 Gentoo female Biscoe 58 ## 10 Gentoo male Biscoe 61 It's not too easy to compare the numbers here; what about a bar graph (geom_bar())? Based on what we went through in the lecture see if you can figure out what each line is adding to the plot. What do you think facet_wrap() is doing? To figure it out run the code yourself and try changing some of the lines of code. ggplot(penguins_nafree, aes(x = species, fill = sex)) + geom_bar(alpha = 0.8, position = &quot;dodge&quot;) + facet_wrap(~island) + xlab(&quot;&quot;) + theme_linedraw() + ## remember themes... scale_fill_manual(values = c(&quot;cyan4&quot;,&quot;darkorange&quot;), name = &quot;Sex&quot;) We also saw there were a few continuous variables, so let's look at scatter plots (geom_point()). ggplot(data = penguins_nafree, aes(x = bill_length_mm, y = bill_depth_mm)) + geom_point(aes(color = species),size = 2) + scale_color_manual(values = c(&quot;darkorange&quot;,&quot;darkorchid&quot;,&quot;cyan4&quot;), name = &quot;&quot;) + theme_bw() + ## Oo a new theme xlab(&quot;Bill length (mm)&quot;) + ylab(&quot;Bill length (mm)&quot;) What about the spread/distribution of our continuous variables by the factor variables (e.g., species): Boxplots (geom_boxplot())? Violin plots (geom_violin())? Histograms (geom_histogram())? In addition,we should always avoid using similarly bight red and green colours: they may not be distinguishable for red-green colorblind readers. Using ggplot2 we can access a whole range of colourblind friendly palettes: one package that has a whole range is RColorBrewer install it then try running RColorBrewer::display.brewer.all(colorblindFriendly = TRUE) what do you think you've asked your computer to show you? ## boxplot ggplot(penguins_nafree,aes(x = species, y = flipper_length_mm)) + geom_boxplot() + ylab(&quot;Flipper length (mm)&quot;) + xlab(&quot;&quot;) + theme_classic() ## yet another theme ## violin plot ggplot(penguins_nafree,aes(x = species, y = flipper_length_mm)) + geom_violin() + ylab(&quot;Flipper length (mm)&quot;) + xlab(&quot;&quot;) + theme_minimal() ## soon you could be making your own ## histogram, with a colorblind friendly palette ## try running display.brewer.all(colorblindFriendly = TRUE) ## what do you think it&#39;s doing ggplot(penguins_nafree,aes(x = flipper_length_mm)) + geom_histogram(aes(fill = species), alpha = 0.5, position = &quot;identity&quot;) + xlab(&quot;Flipper length (mm)&quot;) + scale_fill_brewer(palette = &quot;Dark2&quot;, name = &quot;Species&quot;) + theme_light() 2.4.3.2 What do we think about when we look at plots Between group variation Within group variation 2.5 Other resources: optional but recommended Why data sovereignty matters Indigenous Data Sovereignty and Policy Principles of MƒÅori Data Sovereignty ggplot2 cheatsheet Elegant Graphics for Data Analysis Using ggplot2 to communicate your results Teacups, giraffes, and statistics: free online introductory level R and statistics modules "],["hypothesis-testing-and-introduction-to-linear-regression.html", "3 Hypothesis testing and introduction to linear regression 3.1 Learning objectives 3.2 Hypothesis testing 3.3 Power, Significance, and multiple comparisons 3.4 One way ANOVA (ANalysis Of VAriance) using lm() 3.5 üò± p-values üò± (more to come) 3.6 Other resources: optional but recommended", " 3 Hypothesis testing and introduction to linear regression 3.1 Learning objectives Formulate a question/hypothesis to investigate based on the given data Use an appropriate visualization or other summary to motivate and communicate your hypothesis Explain and discuss the limitations of different hypothesis testing techniques (e.g., single and two-sample t-tests, ANOVA, randomisation test) Explain and discuss the limitations of statistical linear regression with a single factor explanatory variable Interpret and communicate the estimated coefficients to both a statistical and non-statistical audience Describe the aims of the following hypothesis tests one-sample t-test two-sample t-test (independent and dependent) randomization test one-way Analysis of Variance (ANOVA) List the aims of hypothesis testing and write out the appropriate null and alternative hypothesis using statistical notation Write R code to carry out an hypothesis test using the appropriate variables in their dataset. Specifically write R code to carry out one-sample t-test two-sample t-test (independent and dependent) randomization test one-way Analysis of Variance (ANOVA) Interpret and communicate the findings of an hypothesis test accurately and concisely List the limitations of the hypothesis in relation to the questions posed by the data State in terms of probability statements the meaning of the power and significance level of an hypothesis test 3.2 Hypothesis testing Using the paua.csv data from CANVAS 3.2.1 The P\\(\\overline{\\text{a}}\\)ua dataset The P\\(\\overline{\\text{a}}\\)ua dataset contains the following variables Age of P\\(\\overline{\\text{a}}\\)ua in years (calculated from counting rings in the cone) Length of P\\(\\overline{\\text{a}}\\)ua shell in centimeters Species of P\\(\\overline{\\text{a}}\\)ua: Haliotis iris (typically found in NZ) and Haliotis australis (less commonly found in NZ) library(tidyverse) paua &lt;- read_csv(&quot;paua.csv&quot;) 3.2.2 One-Sample t-test Do we believe that the average length of P\\(\\overline{\\text{a}}\\)ua shells is 5cm? Well from our sample the average length is 5.192cm ... But what about variation? Enter the Standard Error of the Mean, SEM (*reflects our uncertainty about the mean) \\(= \\frac{\\sigma}{\\sqrt{n}}\\); where \\(\\sigma = \\sqrt{\\frac{\\Sigma_{i = 1}^n(x_i - \\bar{x})^2}{n-1}}\\) (\\(i = 1,...,n\\)) is the standard deviation of the sample, \\(n\\) is the sample size, and \\(\\bar{x}\\) is the sample mean. 3.2.2.1 Calculating \\((x_i - \\bar{x})^2\\) In R sem &lt;- paua %&gt;% summarise(mean = mean(Length), sem = sd(Length)/sqrt(length(Length))) sem ## # A tibble: 1 x 2 ## mean sem ## &lt;dbl&gt; &lt;dbl&gt; ## 1 5.19 0.155 3.2.3 Visualising the uncertainty 3.2.3.1 Why error bars that are \\(\\pm\\) twice the SEM? This is approx. the 95% confidence interval for the population mean The exact 95% CI is given by + Mean \\(\\pm\\) \\(t_{df,1 - \\alpha/2}\\) \\(\\times\\) SEM ( df = degrees of freedom; \\(\\alpha\\) = level of significance) Each mean has its own confidence interval whose width depends on the SEM for that mean When the df (*more on these later) are large (e.g. 30 or greater) and \\(\\alpha\\) = 0.05 \\(t_{df,1 - \\alpha/2}\\) = \\(t_{large,0.975}\\) \\(\\approx\\) 2 Hence, the 95% confidence interval for the population mean is approximately Mean ¬± 2 \\(\\pm\\) SEM So carrying out the test \\(H_0: \\mu = 5\\) vs \\(H_1: \\mu \\neq 5\\) The t-statistic is calculated as follow: \\(\\frac{\\bar{x}- \\mu}{\\text{SEM}}\\) = \\(\\frac{5.1925 - 5}{0.155351}\\) = 1.239 \\(\\bar{x}\\) is the sample mean \\(\\mu\\) is the theoretical value We can compute the p-value corresponding to the absolute value of the t-test statistics (|t|) for the degrees of freedom (df): df = \\(n ‚àí 1 = 60 - 1 = 59\\). Using R t.test(paua$Length, mu = 5 ) ## ## One Sample t-test ## ## data: paua$Length ## t = 1.2391, df = 59, p-value = 0.2202 ## alternative hypothesis: true mean is not equal to 5 ## 95 percent confidence interval: ## 4.881643 5.503357 ## sample estimates: ## mean of x ## 5.1925 The p-vale gives the probability that under our null hypothesis we observe anything as least as extreme as what we did. This probability is \\(\\sim\\) 22%. Do you think what we've observed is likely under the null hypothesis? Does this plot help? 3.2.4 Differences between two means means &lt;- paua %&gt;% group_by(Species) %&gt;% summarise(means = mean(Age)) ## violin plot with transparent points a &lt;- ggplot(paua,aes(x = Species, y = Age)) + geom_violin() + geom_point(alpha = 0.4) + ylab(&quot;Age (years)&quot;) + xlab(&quot;&quot;) + theme_classic() + geom_point(data = means, aes(x = Species, y = means, color = Species), size = 2) + geom_hline(data = means, aes(yintercept = means, color = Species), lty = 2, alpha = 0.5) + theme(legend.position = &quot;none&quot;) + geom_text(data = means, aes(x = Species, y = means + 1, label = paste0(&quot;Species averege = &quot;,round(means,3)), color = Species)) a Calculating the differences between species means: Haliotis australis average - Haliotis iris average = \\(\\mu_{\\text{Haliotis australis}} - \\mu_{\\text{Haliotis iris}}\\) = 7.546 - 4.403 = 3.143. Doesn't really tell us much. The average values are all well and good... but... variation? Recall the SEM from the one-sample t-test? The same idea holds here, although the calculation is a little bit more complicated (as we have to think about the number of observations in each group). But from the two group SEMs we can calculate the Standard Error of the Difference between two means, SED. 3.2.4.1 Independent samples t-test with lm() and t.test() Null hypothesis: \\(H_0\\) (are on average the same age) verses the alternative hypothesis, \\(H_1\\), that they aren't! \\(H_0: \\mu_{\\text{Haliotis iris}} - \\mu_{\\text{Haliotis australis}} = 0\\) vs \\(H_1: \\mu_{\\text{Haliotis iris}} \\neq \\mu_{\\text{Haliotis australis}}\\) Test Statistic: t-statistic = \\(\\frac{\\bar{x}_{\\text{difference}} - \\mu}{\\text{SED}}\\) = \\(\\frac{\\bar{x}_{\\text{difference}} - 0}{\\text{SED}}\\) = where \\(\\bar{x}_{\\text{difference}}\\) is the differences between the species` averages. Probability of getting a t-statistic at least as extreme as the one we observe (more on this later) test &lt;- t.test(Age ~ Species, data = paua) test ## ## Welch Two Sample t-test ## ## data: Age by Species ## t = 7.2777, df = 44.807, p-value = 4.051e-09 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## 2.273123 4.013024 ## sample estimates: ## mean in group Haliotis australis mean in group Haliotis iris ## 7.545939 4.402866 t.lm &lt;- lm(Age ~ Species, data = paua) summary(t.lm) ## ## Call: ## lm(formula = Age ~ Species, data = paua) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.9050 -0.9227 -0.0752 0.5973 5.5988 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 7.5459 0.3256 23.174 &lt; 2e-16 *** ## SpeciesHaliotis iris -3.1431 0.4204 -7.477 4.63e-10 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.595 on 58 degrees of freedom ## Multiple R-squared: 0.4908, Adjusted R-squared: 0.482 ## F-statistic: 55.9 on 1 and 58 DF, p-value: 4.631e-10 ## changing the baseline ## it&#39;s the ordering that makes the difference paua_rl &lt;- paua %&gt;% mutate(Species = fct_relevel(Species, &quot;Haliotis iris&quot;, &quot;Haliotis australis&quot;)) c.lm &lt;- lm(Age ~ Species, data = paua_rl) summary(c.lm) ## ## Call: ## lm(formula = Age ~ Species, data = paua_rl) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.9050 -0.9227 -0.0752 0.5973 5.5988 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 4.4029 0.2659 16.560 &lt; 2e-16 *** ## SpeciesHaliotis australis 3.1431 0.4204 7.477 4.63e-10 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.595 on 58 degrees of freedom ## Multiple R-squared: 0.4908, Adjusted R-squared: 0.482 ## F-statistic: 55.9 on 1 and 58 DF, p-value: 4.631e-10 3.2.4.2 Inference lm() summary(c.lm)$coef ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 4.402866 0.2658700 16.56022 1.190603e-23 ## SpeciesHaliotis australis 3.143073 0.4203774 7.47679 4.630689e-10 (Intercept) = \\(\\mu_\\text{Haliotis iris}\\) = 4.4028662 SE of (Intercept) = SE of \\(\\mu_\\text{Haliotis iris}\\) = SEM = 0.26587 \\(\\text{SpeciesHaliotis australis}\\) = \\(\\mu_\\text{Haliotis australis}\\) ‚Äì \\(\\mu_\\text{Haliotis iris}\\) = 3.1430733 SE of \\(\\text{SpeciesHaliotis australis}\\) = SE of (\\(\\mu_\\text{Haliotis australis}\\) ‚Äì \\(\\mu_\\text{Haliotis iris}\\) ) = SED = 0.4203774 Hypotheses being tested The t value and Pr (&gt;|t|) are the t - and p-value for testing the null hypotheses: Mean abundance is zero for Haliotis iris (not interested in this really) No difference between the population means of Haliotis iris and Haliotis australis 3.2.4.3 Randomization test The basic approach to randomization tests is straightforward: Decide on a metric to measure the effect in question (e.g., differences between group means) Calculate that test statistic on the observed data. Note this metric can be anything you wish For chosen number of times (i.e., nreps below) Shuffle the data labels Calculate the test statistic for the reshuffled data and retain Calculate the proportion of times your reshuffeled statistics equal or exceed the observed typically here we use the absolute values as we'd be carrying out a two-tailed test this is the probability of such an extreme result under the null Reject or retain the null on the basis of this probability. Randomization Test on Two Independent Samples Do average lengths differ between Species? means &lt;- paua %&gt;% group_by(Species) %&gt;% summarise(means = mean(Length)) ggplot(paua,aes(x = Species, y = Length)) + geom_violin() + geom_point(alpha = 0.4) + ylab(&quot;Length (cms)&quot;) + xlab(&quot;&quot;) + theme_classic() + geom_point(data = means, aes(x = Species, y = means, color = Species), size = 2) + geom_hline(data = means, aes(yintercept = means, color = Species), lty = 2, alpha = 0.5) + theme(legend.position = &quot;none&quot;) + geom_text(data = means, aes(x = Species, y = means + 1, label = paste0(&quot;Species averege = &quot;,round(means,3)), color = Species)) ggplot(paua,aes(x = Length, fill = Species)) + geom_histogram(position = &quot;identity&quot;, alpha = 0.3) + xlab(&quot;Length (cms)&quot;) + ylab(&quot;&quot;) + theme_classic() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. But because the data are skewed and we've likely got non-constant variances we be better off adopting a randomization test, rather than a parametric t-test ## observed differences in means diff_in_means &lt;- (paua %&gt;% group_by(Species) %&gt;% summarise(mean = mean(Length)) %&gt;% summarise(diff = diff(mean)))$diff diff_in_means ## [1] -0.9569444 ## Number of times I want to randomise nreps &lt;- 1000 ## initialize empty array to hold results randomisation_difference_mean &lt;- numeric(nreps) set.seed(1234) ## *****Remove this line for actual analyses***** ## This means that each run with produce the same results and ## agree with the printout that I show. for (i in 1:nreps) { ## the observations data &lt;- data.frame(value = paua$Length) ## randomise labels data$random_labels &lt;-sample(paua$Species, replace = FALSE) ## randomised differences in mean randomisation_difference_mean[i] &lt;- (data %&gt;% group_by(random_labels) %&gt;% summarise(mean = mean(value)) %&gt;% summarise(diff = diff(mean)))$diff } ## results results &lt;- data.frame(randomisation_difference_mean = randomisation_difference_mean) Interpreting p-values for a randomisation test ## How many randomised differences in means are as least as extreme as the one we observed ## absolute value as dealing with two tailed n_exceed &lt;- sum(abs(results$randomisation_difference_mean) &gt;= abs(diff_in_means)) n_exceed ## [1] 1 ## proportion n_exceed/nreps ## [1] 0.001 ggplot(results, aes(x = randomisation_difference_mean)) + geom_histogram() + theme_classic() + ylab(&quot;&quot;) + xlab(&quot;Differences between randomised group means&quot;) + geom_vline(xintercept = diff_in_means, col = &quot;cyan4&quot;, size = 1,alpha = 0.6) + annotate(geom = &#39;text&#39;, label = &quot;Observed difference between means&quot; , x = -Inf, y = Inf, hjust = 0, vjust = 1.5, color = &quot;cyan4&quot;) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. How would the parametirc t-test have served? t.test(Length ~ Species, data = paua) ## ## Welch Two Sample t-test ## ## data: Length by Species ## t = 3.5404, df = 57.955, p-value = 0.0007957 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## 0.4158802 1.4980086 ## sample estimates: ## mean in group Haliotis australis mean in group Haliotis iris ## 5.766667 4.809722 Not too different after all In experimental situations a large p-value (large tail proportion) means that the luck of the randomisation quite often produces group differences as large or even larger than what we‚Äôve got in our data. A small p-value means that the luck of the randomisation draw hardly ever produces group differences as large as we‚Äôve got in our data. Statistical significance does not imply practical significance. Statistical significance says nothing about the size of treatment differences. To estimate the sizes of differences you need confidence intervals. NOTE: We can extend the randomization test to make inference about any sample statistic (not just the mean) 3.3 Power, Significance, and multiple comparisons Recall, we have two competing hypotheses (claims) relating to the true vale of some population characteristic (e.g., the population mean, denoted \\(\\mu\\)): Type I error (false positive): declare a difference (i.e., reject \\(H_0\\)) when there is no difference (i.e. \\(H_0\\) is true). Risk of the Type I error is determined by the level of significance (which we set!) (i.e., \\(\\alpha =\\text{ P(Type I error)} = \\text{P(false positive)}\\). Artwork by @allison_horst Type II error (false negative): difference not declared (i.e., \\(H_0\\) not rejected) when there is a difference (i.e., \\(H_0\\) is false). Let \\(\\beta =\\) P(do not reject \\(H_0\\) when \\(H_0\\) is false); so, \\(1-\\beta\\) = P(reject \\(H_0\\) when \\(H_0\\) is false) = P(a true positive), which is the statistical power of the test. Artwork by @allison_horst Significance level = probability of a Type I error = probability of finding an effect that is not there (false positive). Power: the probability that the test correctly rejects the null hypothesis when the alternative hypothesis is true. probability of finding an effect that is there = 1 - probability of a Type II error (false negative). Reducing the chance of a Type I error increases the chance of a Type II error. They are inversely related. Type II error rate is determined by a combination of the following. Effect size (size of difference, of biological significance) between the true population parameters Experimental error variance Sample size Choice of Type I error rate (\\(\\alpha\\)) Each time we carry out a hypothesis test the probability we get a false positive result (Type I error) is given by \\(\\alpha\\) (the level of significance we choose). When we have multiple comparisons to make we should then control the Type I error rate across the entire family of tests under consideration, i.e., control the Family-Wise Error Rate (FWER); this ensures that the risk of making at least one Type I error among the family of comparisons in the experiment is \\(\\alpha\\). 3.4 One way ANOVA (ANalysis Of VAriance) using lm() Key assumptions of Analysis of Variance Observations are independent Check experiment description How were data collected? All observations have the same variance Spread of the observations does not depend on the Treatment Mean All observations are (approximately) normally distributed. Remember the penguins? fit.lm &lt;- lm(bill_length_mm ~ species, data = penguins) summary(fit.lm) ## ## Call: ## lm(formula = bill_length_mm ~ species, data = penguins) ## ## Residuals: ## Min 1Q Median 3Q Max ## -7.9338 -2.2049 0.0086 2.0662 12.0951 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 38.7914 0.2409 161.05 &lt;2e-16 *** ## speciesChinstrap 10.0424 0.4323 23.23 &lt;2e-16 *** ## speciesGentoo 8.7135 0.3595 24.24 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.96 on 339 degrees of freedom ## (2 observations deleted due to missingness) ## Multiple R-squared: 0.7078, Adjusted R-squared: 0.7061 ## F-statistic: 410.6 on 2 and 339 DF, p-value: &lt; 2.2e-16 Taking species Adelie as the baseline.. Which pairs of means are different? Pair-wise comparisons of means Use two-sample t-tests We need to calculate our observed t-value where \\(\\text{t-value} = \\frac{\\text{Sample Difference}_{ij} - \\text{Difference assuming } H_0 \\text{ is true}_{ij}}{\\text{SE of } \\text{Sample Difference}_{ij}}\\) where \\(\\text{Sample Difference}_{ij}\\) = Difference between pair of sample means Compute the p-value for observed t-value summary(fit.lm)$coef ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 38.791391 0.2408694 161.04737 2.470328e-322 ## speciesChinstrap 10.042433 0.4322643 23.23216 4.232862e-72 ## speciesGentoo 8.713487 0.3595046 24.23749 5.330682e-76 (Intercept) = \\(\\text{mean}_{\\text{Adelie}}\\) = 38.7913907 SE of (Intercept) = SE of \\(\\text{mean}_{\\text{Adelie}\\) = SEM = 38.7913907 \\(\\text{speciesChinstrap}\\) = \\(\\text{mean}_{\\text{Chinstrap}}\\) - \\(\\text{mean}_{\\text{Adelie}}\\) = 10.0424328 SE of \\(\\text{speciesChinstrap}\\) = SE of (\\(\\text{mean}_{\\text{Chinstrap}}\\) - \\(\\text{mean}_{\\text{Adelie}}\\) ) = SED = 0.4322643 What is \\(\\text{mean}_{\\text{Gentoo}}\\) - \\(\\text{mean}_{\\text{Adelie}}\\) Hypotheses being tested The t value and Pr (&gt;|t|) are the t - and p-value for testing the null hypotheses: Mean abundance is zero for Adelie population No difference between the population means of Chinstrap and Adelie No difference between the population means of Gentoo and Adelie We‚Äôre interested in 2 and 3, but not necessarily 1! 3.4.1 Model diagnostics and data transformations Observations are independent Check experiment description How were data collected? All observations have the same variance Spread of the observations does not depend on the Treatment Mean All observations are (approximately) normally distributed. Residual plot to evaluate homogeneity of variances assumption Plot residuals against the estimated values of the treatment means (Predicted Values) If the variability of the observations around the treatment means differs between groups, this will be reflected in the residual plot resids &lt;- data.frame(Residuals = residuals(fit.lm)) # Extract predicted (fitted) values and add to the data frame resids$Fitted.Values &lt;- fitted.values(fit.lm) Other diagnostic plots gglm::gglm(fit.lm) # Plot the four main diagnostic plots ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : pseudoinverse used at 38.741 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : neighborhood radius 8.7637 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : reciprocal condition number 3.8046e-30 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : There are other near singularities as well. 101.86 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : pseudoinverse used at 0.0065821 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : neighborhood radius 0.001548 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : reciprocal condition number 1.3674e-15 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : There are other near singularities as well. 6.5996e-05 QQplot Normal quantile-quantile (QQ) plot ‚Ä¢ Plot sorted residuals versus expected order statistics from a standard normal distribution Samples should be close to a line Points moving away from 45 degree line at the tails suggest the data are from a skewed distribution, but it is difficult to be confident with so few data points Outliers: Causes Errors in collecting and/or recording of data Mistakes in technique Treatment and/or environment Affect statistical inference Inflation of estimated experimental error variance Influence estimate of treatment mean Investigate cause before discarding data Discarded data results in loss of information Looking for outliers with residuals Large positive or negative values far removed from the 1-to-1 line in the normal QQ plot Points far removed from upper and lower boundaries of the Residuals versus Predicted values plot Variance stabilizing transformations Used to change the scale of the observations To conform more closely with the ANOVA assumptions To provide more valid inferences from ANOVA Significance levels (\\(\\alpha\\)) don't apply to original data Conduct analysis and make all inferences on transformed Present summary tables on the original measurement scale 3.5 üò± p-values üò± (more to come) &quot;Good statistical practice, as an essential component of good scientific practice, emphasizes principles of good study design and conduct, a variety of numerical and graphical summaries of data, understanding of the phenomenon under study, interpretation of results in context, complete reporting and proper logical and quantitative understanding of what data summaries mean. No single index should substitute for scientific reasoning.&quot; --- ASA Statement on p-Values **What is a p-Value?** Informally, a p-value is the probability under a specified statistical model that a statistical summary of the data (e.g., the sample mean difference between two compared groups) would be equal to or more extreme than its observed value p-values can indicate how incompatible the data are with a specified statistical model p-values do not measure the probability that the studied hypothesis is true, or the probability that the data were produced by random chance alone scientific conclusions and business or policy decisions should not be based only on whether a p-value passes a specific threshold roper inference requires full reporting and transparency p-value, or statistical significance, does not measure the size of an effect or the importance of a result by itself, a p-value does not provide a good measure of evidence regarding a model or hypothesis Example Two-sample t -tests for pairwise comparisons of means: $ : t value = Estimate √∑ Std.Error = 23.23; Pr (&gt;|t|) = &lt;2e-16 3.6 Other resources: optional but recommended Teacups, giraffes, and statistics: free online introductory level R and statistics modules I thought it could be helpful to have a thread on ANOVA in R. As a statistical consultant, this is the most frequent FAQ I get from clients - how to run a linear model on their data, conduct hypothesis tests, extract predicted means and perform contrasts. ‚Äî We are R-Ladies (@WeAreRLadies) February 2, 2020 The ASA Statement on p-Values: Context, Process, and Purpose "]]
